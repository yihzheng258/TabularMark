{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "# p = 2 # size of candidate set\n",
    "n = 400 # number of key cells\n",
    "gamma = 1/2 # ratio between the length of green domain and red domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [5 2 1 7 3 6 4]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "2    283301\n",
      "1    211840\n",
      "3     35754\n",
      "7     20510\n",
      "6     17367\n",
      "5      9493\n",
      "4      2747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show info of dataset\n",
    "import pandas as pd\n",
    "\n",
    "# 数据集文件路径\n",
    "file_path = '/home/zhengyihao/dataset/covertype/covtype.data'\n",
    "\n",
    "# 根据所提供的信息，创建一个包含所有列名的列表\n",
    "column_names = [\n",
    "    'Elevation', 'Aspect', 'Slope',\n",
    "    'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "    'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "\n",
    "# 添加Wilderness_Area的4个二进制列\n",
    "wilderness_areas = ['Wilderness_Area' + str(i) for i in range(1, 5)]\n",
    "column_names += wilderness_areas\n",
    "\n",
    "# 添加Soil_Type的40个二进制列\n",
    "soil_types = ['Soil_Type' + str(i) for i in range(1, 41)]\n",
    "column_names += soil_types\n",
    "\n",
    "# 添加Cover_Type列\n",
    "column_names.append('Cover_Type')\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path, names=column_names)\n",
    "\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 使用random模块生成n个随机数种子\n",
    "seeds = [random.randrange(4294967296) for _ in range(n)]  # 4294967296是2的32次方\n",
    "\n",
    "# 将生成的种子保存到文件中\n",
    "with open('tabularmark_seed.txt', 'w') as f:\n",
    "    for seed in seeds:\n",
    "        f.write(str(seed) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400个随机索引已生成并保存到文件 'tabularmark_index.txt' 中。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "if len(data) < n:\n",
    "    raise ValueError(\"data中的记录数小于所请求的n个记录\")\n",
    "\n",
    "random_indices = random.sample(range(len(data)), n)\n",
    "\n",
    "with open('tabularmark_index.txt', 'w') as findex:\n",
    "    for index in random_indices:\n",
    "        findex.write(str(index) + '\\n')\n",
    "\n",
    "print(f\"{n}个随机索引已生成并保存到文件 'tabularmark_index.txt' 中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate candidate set for every key cell\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 假设df是你的DataFrame，已包含Cover_Type属性列\n",
    "# 假设Cover_Type允许的所有可能的类别值已被加载到cover_types列表中\n",
    "\n",
    "# 加载索引列表\n",
    "with open('tabularmark_index.txt', 'r') as f:\n",
    "    indices = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "# 加载种子列表\n",
    "with open('tabularmark_seed.txt', 'r') as f:\n",
    "    seeds = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "df = data\n",
    "cover_types = data['Cover_Type'].unique()\n",
    " \n",
    "# 验证索引列表和种子列表的长度是否一致\n",
    "if len(indices) != len(seeds):\n",
    "    raise ValueError(\"索引文件和种子文件的长度不一致\")\n",
    "\n",
    "# 开始替换Cover_Type值\n",
    "for idx, seed in zip(indices, seeds):\n",
    "    random.seed(seed)\n",
    "    candidate_set = cover_types\n",
    "     # 打乱cover_types的顺序\n",
    "    shuffled_cover_types = list(cover_types)\n",
    "    random.shuffle(shuffled_cover_types)\n",
    "\n",
    "    # 确保cover_types能被划分为两个相等大小的部分\n",
    "    half_size = len(shuffled_cover_types) // 2\n",
    "\n",
    "    # 划分成green_domain和red_domain\n",
    "    green_domain = shuffled_cover_types[:half_size]\n",
    "    red_domain = shuffled_cover_types[half_size:]\n",
    "\n",
    "    perturb_value = random.choice(green_domain)\n",
    "\n",
    "    # 将df中对应索引的Cover_Type属性替换为这个选定的值\n",
    "    df.loc[idx, 'Cover_Type'] = perturb_value\n",
    "    \n",
    "df.to_csv('/home/zhengyihao/dataset/covertype/tabularmark_covertype.data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "The z-score is  20.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# define hyperparameters\n",
    "# p = 2 # size of candidate set\n",
    "n = 400 # number of key cells\n",
    "gamma = 1/2 # ratio between the length of green domain and red domain\n",
    "\n",
    "green_cell = 0\n",
    "\n",
    "file_path = '/home/zhengyihao/dataset/covertype/tabularmark_covertype.data.csv'\n",
    "detected_data = pd.read_csv(file_path)\n",
    "\n",
    "# 加载索引列表\n",
    "with open('tabularmark_index.txt', 'r') as f:\n",
    "    indices = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "# 加载种子列表\n",
    "with open('tabularmark_seed.txt', 'r') as f:\n",
    "    seeds = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "df = detected_data\n",
    "cover_types = detected_data['Cover_Type'].unique()\n",
    "\n",
    "\n",
    "# 开始替换Cover_Type值\n",
    "for idx, seed in zip(indices, seeds):\n",
    "    random.seed(seed)\n",
    "    candidate_set = cover_types\n",
    "     # 打乱cover_types的顺序\n",
    "    shuffled_cover_types = list(cover_types)\n",
    "    random.shuffle(shuffled_cover_types)\n",
    "\n",
    "    # 确保cover_types能被划分为两个相等大小的部分\n",
    "    half_size = len(shuffled_cover_types) // 2\n",
    "\n",
    "    # 划分成green_domain和red_domain\n",
    "    green_domain = shuffled_cover_types[:half_size]\n",
    "    red_domain = shuffled_cover_types[half_size:]\n",
    "\n",
    "    if df.loc[idx, 'Cover_Type'] in green_domain:\n",
    "        green_cell += 1\n",
    "    \n",
    "print(green_cell)\n",
    "\n",
    "# calculate z-score\n",
    "z_score = (green_cell - n/2) / math.sqrt(n/4)\n",
    "\n",
    "print(\"The z-score is \",z_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
