{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [5 2 1 7 3 6 4]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "2    283301\n",
      "1    211840\n",
      "3     35754\n",
      "7     20510\n",
      "6     17367\n",
      "5      9493\n",
      "4      2747\n",
      "Name: count, dtype: int64\n",
      "Generated 16 bits private key:  c002\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "# show info of dataset\n",
    "import pandas as pd\n",
    "\n",
    "# 数据集文件路径\n",
    "file_path = '/home/zhengyihao/dataset/covertype/covtype.data'\n",
    "\n",
    "# 根据所提供的信息，创建一个包含所有列名的列表\n",
    "column_names = [\n",
    "    'Elevation', 'Aspect', 'Slope',\n",
    "    'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "    'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "\n",
    "# 添加Wilderness_Area的4个二进制列\n",
    "wilderness_areas = ['Wilderness_Area' + str(i) for i in range(1, 5)]\n",
    "column_names += wilderness_areas\n",
    "\n",
    "# 添加Soil_Type的40个二进制列\n",
    "soil_types = ['Soil_Type' + str(i) for i in range(1, 41)]\n",
    "column_names += soil_types\n",
    "\n",
    "# 添加Cover_Type列\n",
    "column_names.append('Cover_Type')\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path, names=column_names)\n",
    "\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)\n",
    "\n",
    "\n",
    "\n",
    "# 在原始数据上加上 primary key列\n",
    "# 通过reset_index函数为数据集添加索引列，这列就是“primary_key”\n",
    "data = data.reset_index()\n",
    "\n",
    "# 设置新的列名，将之前的index变为 primary_key\n",
    "data = data.rename(columns={'index':'primary_key'})\n",
    "\n",
    "# 将新的数据帧保存到硬盘上\n",
    "data.to_csv('/home/zhengyihao/dataset/covertype/covtype_with_key.data', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# 定义用户私钥 Ks\n",
    "import secrets\n",
    "\n",
    "# 生成 16 bits 的随机密钥\n",
    "Ks = secrets.token_hex(2)\n",
    "\n",
    "print(\"Generated 16 bits private key: \", Ks)\n",
    "\n",
    "\n",
    "\n",
    "# 定义水印长度 l 与组数 N_g（数值相同）\n",
    "l = 400\n",
    "N_g = 400\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分组\n",
    "import hashlib\n",
    "\n",
    "def hash_function(Ks, PK, N_g):\n",
    "    # 使用sha256作为哈希函数\n",
    "    hash_obj = hashlib.sha256()\n",
    "    # 计算H(Ks|tu.PK)\n",
    "    inner_value = (str(Ks) + str(PK)).encode('utf-8')\n",
    "    hash_obj.update(inner_value)\n",
    "    inner_hash = hash_obj.hexdigest()\n",
    "    # 计算H(Ks|H(Ks|tu.PK))\n",
    "    outer_value = (str(Ks) + inner_hash).encode('utf-8')\n",
    "    hash_obj.update(outer_value)\n",
    "    outer_hash = hash_obj.hexdigest()\n",
    "    # 组别序号\n",
    "    group_number = int(outer_hash, 16) % N_g\n",
    "    return group_number\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据集\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/covtype_with_key.data')\n",
    "\n",
    "# 应用 hash 函数\n",
    "data['group_number'] = data['primary_key'].apply(lambda x: hash_function(Ks, x, N_g))\n",
    "\n",
    "# 按 group_number 排序重置\n",
    "sorted_data = data.sort_values(by='group_number')\n",
    "\n",
    "# 将结果保存到新的 CSV 文件\n",
    "sorted_data.to_csv('/home/zhengyihao/dataset/covertype/covtype_with_group.data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_number\n",
      "0      1428\n",
      "1      1474\n",
      "2      1445\n",
      "3      1477\n",
      "4      1477\n",
      "       ... \n",
      "395    1440\n",
      "396    1474\n",
      "397    1541\n",
      "398    1546\n",
      "399    1384\n",
      "Length: 400, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# 加载数据集\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/covtype_with_group.data')\n",
    "\n",
    "# 统计每个组的 tuples 的数量\n",
    "group_counts = data.groupby('group_number').size()\n",
    "\n",
    "# 打印统计结果\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要嵌入的水印信息是 0111100011010110111011111111001111001000001100110100111011111011010101000110110111111111101100011011110001101001101101100010010001110111010010000011101110000011101001001010011011001010100001010110011011101001100101110011001000100101101010110010011001100001010001101000000111010100100101100010001100101001011011010111010111010010101001101001000011101011110000100010101010111100010110110111101001110110\n",
      "Count of 1:  208\n",
      "Count of 0:  192\n"
     ]
    }
   ],
   "source": [
    "# 生成嵌入水印信息\n",
    "\n",
    "import random\n",
    "\n",
    "# 生成一个长度为 400 的字符串，它由随机的 0 和 1 组成\n",
    "watermark = ''.join(random.choice('01') for _ in range(400))\n",
    "# 打印二进制字符串\n",
    "print(\"要嵌入的水印信息是\",watermark)\n",
    "\n",
    "# 统计二进制字符串中 1 的个数\n",
    "count_1 = watermark.count('1')\n",
    "\n",
    "# 统计二进制字符串中 0 的个数\n",
    "count_0 = watermark.count('0')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Count of 1: \", count_1)\n",
    "print(\"Count of 0: \", count_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 初始化 group_number\n",
    "group_number = 0\n",
    "_max = data['Cover_Type'].max()\n",
    "_min = data['Cover_Type'].min()\n",
    "\n",
    "# 创建 y_hat 列\n",
    "data['y_hat'] = (_max + _min) / 2\n",
    "pa = {}\n",
    "mp = []\n",
    "\n",
    "for bit in watermark:\n",
    "    # 选取当前 group 的数据\n",
    "    mask = data['group_number'] == group_number\n",
    "    group_data = data[mask]\n",
    "\n",
    "    # 计算 p_e (忽略 min 和 max)\n",
    "    mask2 = (group_data['Cover_Type'] != _max) & (group_data['Cover_Type'] != _min)\n",
    "    p_e = group_data.loc[mask2, 'Cover_Type'] - group_data.loc[mask2, 'y_hat']\n",
    "\n",
    "    # 使用 Counter 统计每个 p_e 出现的频数\n",
    "    counter = Counter(np.abs(p_e))\n",
    "\n",
    "    # 找出出现频数最高的 p_e 并赋值给 p\n",
    "    p = counter.most_common(1)[0][0]\n",
    "\n",
    "    # 把当前 group 中, Cover_Type 为 min 或 max 的 primary_key 存入 mp\n",
    "    mask_min_or_max = (group_data['Cover_Type'] == _max) | (group_data['Cover_Type'] == _min)\n",
    "    mp.extend(group_data.loc[mask_min_or_max, 'primary_key'].values.tolist())\n",
    "\n",
    "    # 对于那些不等于 min 或 max 的 'Cover_Type'，更新原始数据集数据\n",
    "    mask &= mask2\n",
    "\n",
    "    group_cover_type = data.loc[mask, 'Cover_Type']\n",
    "    y_hat = (_max + _min) / 2\n",
    "    p_e = group_cover_type - y_hat\n",
    "\n",
    "    # 更新 p_e 的值\n",
    "    p_e = np.where((p_e == p) & (bit == '0'), p_e,\n",
    "                   np.where((p_e == p) & (bit == '1'), p_e + 1,\n",
    "                            np.where((p_e == -p) & (bit == '0'), p_e,\n",
    "                                     np.where((p_e == -p) & (bit == '1'), p_e - 1,\n",
    "                                              np.where(p_e >= p + 1, p_e + 1,\n",
    "                                                       np.where(p_e <= -(p + 1), p_e - 1, p_e))))))\n",
    "\n",
    "    # 计算 y_prime，并更新 'Cover_Type'\n",
    "    data.loc[mask, 'Cover_Type'] = p_e + y_hat\n",
    "\n",
    "    pa[group_number] = p\n",
    "\n",
    "    # 更新 group_number 到下一组\n",
    "    group_number += 1\n",
    "\n",
    "data.to_csv('/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [2 1 3 6 4 5 7]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "1    359075\n",
      "2    136066\n",
      "3     35754\n",
      "7     29589\n",
      "5      9493\n",
      "6      8288\n",
      "4      2747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv'\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m p \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mget(group_number)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mp:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pe \u001b[38;5;241m==\u001b[39m p:\n\u001b[1;32m     30\u001b[0m         w_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pe \u001b[38;5;241m==\u001b[39m p\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m pe \u001b[38;5;241m==\u001b[39m p\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#提取水印\n",
    "file_path = '/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv'\n",
    "detected_data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "_max = detected_data['Cover_Type'].max()\n",
    "_min = detected_data['Cover_Type'].min()\n",
    "y_hat = (_max + _min) / 2\n",
    "\n",
    "group_number = 0\n",
    "\n",
    "W_det = \"\"\n",
    "\n",
    "for bit in watermark:\n",
    "    w_det = 0\n",
    "    mask = detected_data['group_number'] == group_number\n",
    "    group_data = detected_data[mask]\n",
    "    a = 0 # count bit = 0\n",
    "    b = 0 # count bit = 1\n",
    "    for _,row in group_data.iterrows():\n",
    "        pe = row['Cover_Type'] - y_hat\n",
    "        p = pa.get(group_number)\n",
    "        if row['primary_key'] not in mp:\n",
    "            if pe == p:\n",
    "                w_det = 0\n",
    "            elif pe == p+1 or pe == p-1:\n",
    "                w_det = 1\n",
    "\n",
    "            if w_det == 1:\n",
    "                b += 1\n",
    "            else:\n",
    "                a += 1\n",
    "    if a > b:\n",
    "        w_det = 0\n",
    "    else:\n",
    "        w_det = 1\n",
    "    print(w_det)\n",
    "    W_det += str(w_det)\n",
    "\n",
    "    group_number += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m detected_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpe\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m detected_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCover_Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m y_hat\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 将原有的list类型转化为集合数据类型，提高在其中查找项的速度\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m mp_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mmp\u001b[49m)\n\u001b[1;32m     17\u001b[0m W_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group_number, bit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(watermark):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 对当前组进行操作\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv'\n",
    "detected_data = pd.read_csv(file_path)\n",
    "\n",
    "# 计算 y_hat\n",
    "_max = detected_data['Cover_Type'].max()\n",
    "_min = detected_data['Cover_Type'].min()\n",
    "y_hat = (_max + _min) / 2\n",
    "\n",
    "# 计算 pe 值\n",
    "detected_data['pe'] = detected_data['Cover_Type'] - y_hat\n",
    "\n",
    "# 将原有的list类型转化为集合数据类型，提高在其中查找项的速度\n",
    "mp_set = set(mp)\n",
    "W_det = \"\"\n",
    "\n",
    "for group_number, bit in enumerate(watermark):\n",
    "    # 对当前组进行操作\n",
    "    group_data = detected_data[detected_data['group_number'] == group_number]\n",
    "    p = pa[group_number]\n",
    "\n",
    "    a = 0 # count bit = 0\n",
    "    b = 0 # count bit = 1\n",
    "\n",
    "    # 通过将一组条件（每行是否满足要求）应用于数据框并进行求和，避免了逐行运算\n",
    "    mask = ~group_data['primary_key'].isin(mp_set) & ((group_data['pe'] == p+1) | (group_data['pe'] == p-1))\n",
    "    b = mask.sum()\n",
    "    mask = ~group_data['primary_key'].isin(mp_set) & (group_data['pe'] == p)\n",
    "    a = mask.sum()\n",
    "\n",
    "    W_det += '0' if a > b else '1'\n",
    "print(W_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'watermark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m percentage\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# W = '1010101010'\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# W_det = '1010001010'\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mwatermark\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW_det: \u001b[39m\u001b[38;5;124m\"\u001b[39m,W_det)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMismatch Percentage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmismatch_percentage(watermark,\u001b[38;5;250m \u001b[39mW_det)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'watermark' is not defined"
     ]
    }
   ],
   "source": [
    "#计算 BER\n",
    "def mismatch_percentage(W, W_det):\n",
    "    # 首先检查 W 和 W_det 是否长度相同\n",
    "    if len(W) != len(W_det):\n",
    "        print('Error: The lengths of W and W_det are not the same!')\n",
    "        return\n",
    "    # 计算不匹配度\n",
    "    count_mismatch = sum(a != b for a, b in zip(W, W_det))\n",
    "    percentage = count_mismatch / len(W)\n",
    "    return percentage\n",
    "\n",
    "# W = '1010101010'\n",
    "# W_det = '1010001010'\n",
    "print(\"W: \",watermark)\n",
    "print(\"W_det: \",W_det)\n",
    "print(f'Mismatch Percentage: {mismatch_percentage(watermark, W_det):.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
