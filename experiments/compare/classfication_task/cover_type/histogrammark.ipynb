{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [5 2 1 7 3 6 4]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "5    2000\n",
      "2    2000\n",
      "1    2000\n",
      "7    2000\n",
      "3    2000\n",
      "6    2000\n",
      "4    2000\n",
      "Name: count, dtype: int64\n",
      "Generated 16 bits private key:  d751\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "# show info of dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/covtype_with_key.subset.data')\n",
    "\n",
    "# 定义用户私钥 Ks\n",
    "import secrets\n",
    "\n",
    "# 生成 16 bits 的随机密钥\n",
    "Ks = secrets.token_hex(2)\n",
    "\n",
    "print(\"Generated 16 bits private key: \", Ks)\n",
    "\n",
    "# 定义水印长度 l 与组数 N_g（数值相同）\n",
    "l = 400\n",
    "N_g = 400  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分组\n",
    "import hashlib\n",
    "\n",
    "def hash_function(Ks, PK, N_g):\n",
    "    # 使用sha256作为哈希函数\n",
    "    hash_obj = hashlib.sha256()\n",
    "    # 计算H(Ks|tu.PK)\n",
    "    inner_value = (str(Ks) + str(PK)).encode('utf-8')\n",
    "    hash_obj.update(inner_value)\n",
    "    inner_hash = hash_obj.hexdigest()\n",
    "    # 计算H(Ks|H(Ks|tu.PK))\n",
    "    outer_value = (str(Ks) + inner_hash).encode('utf-8')\n",
    "    hash_obj.update(outer_value)\n",
    "    outer_hash = hash_obj.hexdigest()\n",
    "    # 组别序号\n",
    "    group_number = int(outer_hash, 16) % N_g\n",
    "    return group_number\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/covtype_with_key.subset.data')\n",
    "\n",
    "# 应用 hash 函数\n",
    "data['group_number'] = data['primary_key'].apply(lambda x: hash_function(Ks, x, N_g))\n",
    "\n",
    "# 按 group_number 排序重置\n",
    "sorted_data = data.sort_values(by='group_number')\n",
    "\n",
    "# 将结果保存到新的 CSV 文件\n",
    "sorted_data.to_csv('/home/zhengyihao/dataset/covertype/covtype_with_group.data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_number\n",
      "0      38\n",
      "1      48\n",
      "2      46\n",
      "3      34\n",
      "4      30\n",
      "       ..\n",
      "395    34\n",
      "396    36\n",
      "397    40\n",
      "398    35\n",
      "399    38\n",
      "Length: 400, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# 加载数据集\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/covtype_with_group.data')\n",
    "\n",
    "# 统计每个组的 tuples 的数量\n",
    "group_counts = data.groupby('group_number').size()\n",
    "\n",
    "# 打印统计结果\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要嵌入的水印信息是 1011110101000101001100100010111011111010101000101101010011100001111001100001010001101001101010110001000010110111001001000000000010010101010111101010110100010010111011100111010000110000000000111101011011001101001010100001100001110111010100100100010011011010000000100011010101100110001000000010101000111010110110011100111001101101111101001001101101100010010100101000100100111101111100000011010011010101\n",
      "Count of 1:  187\n",
      "Count of 0:  213\n",
      "水印信息已保存到 histogram_mark.txt\n"
     ]
    }
   ],
   "source": [
    "# 生成嵌入水印信息\n",
    "\n",
    "import random\n",
    "\n",
    "# 生成一个长度为 400 的字符串，它由随机的 0 和 1 组成\n",
    "watermark = ''.join(random.choice('01') for _ in range(400))\n",
    "# 打印二进制字符串\n",
    "print(\"要嵌入的水印信息是\",watermark)\n",
    "\n",
    "# 统计二进制字符串中 1 的个数\n",
    "count_1 = watermark.count('1')\n",
    "\n",
    "# 统计二进制字符串中 0 的个数\n",
    "count_0 = watermark.count('0')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Count of 1: \", count_1)\n",
    "print(\"Count of 0: \", count_0)\n",
    "\n",
    "# 保存水印信息到文件\n",
    "with open(\"histogram_mark.txt\", \"w\") as file:\n",
    "    file.write(watermark)\n",
    "\n",
    "print(\"水印信息已保存到 histogram_mark.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 初始化 group_number\n",
    "group_number = 0\n",
    "_max = data['Cover_Type'].max()\n",
    "_min = data['Cover_Type'].min()\n",
    "\n",
    "# 创建 y_hat 列\n",
    "data['y_hat'] = (_max + _min) / 2\n",
    "pa = {}\n",
    "mp = []\n",
    "\n",
    "for bit in watermark:\n",
    "    # 选取当前 group 的数据\n",
    "    mask = data['group_number'] == group_number\n",
    "    group_data = data[mask]\n",
    "\n",
    "    # 计算 p_e (忽略 min 和 max)\n",
    "    mask2 = (group_data['Cover_Type'] != _max) & (group_data['Cover_Type'] != _min)\n",
    "    p_e = group_data.loc[mask2, 'Cover_Type'] - group_data.loc[mask2, 'y_hat']\n",
    "\n",
    "    # 使用 Counter 统计每个 p_e 出现的频数\n",
    "    counter = Counter(np.abs(p_e))\n",
    "\n",
    "    # 找出出现频数最高的 p_e 并赋值给 p\n",
    "    p = counter.most_common(1)[0][0]\n",
    "\n",
    "    # 把当前 group 中, Cover_Type 为 min 或 max 的 primary_key 存入 mp\n",
    "    mask_min_or_max = (group_data['Cover_Type'] == _max) | (group_data['Cover_Type'] == _min)\n",
    "    mp.extend(group_data.loc[mask_min_or_max, 'primary_key'].values.tolist())\n",
    "\n",
    "    # 对于那些不等于 min 或 max 的 'Cover_Type'，更新原始数据集数据\n",
    "    mask &= mask2\n",
    "\n",
    "    group_cover_type = data.loc[mask, 'Cover_Type']\n",
    "    y_hat = (_max + _min) / 2\n",
    "    p_e = group_cover_type - y_hat\n",
    "\n",
    "    # 更新 p_e 的值\n",
    "    p_e = np.where((p_e == p) & (bit == '0'), p_e,\n",
    "                   np.where((p_e == p) & (bit == '1'), p_e + 1,\n",
    "                            np.where((p_e == -p) & (bit == '0'), p_e,\n",
    "                                     np.where((p_e == -p) & (bit == '1'), p_e - 1,\n",
    "                                              np.where(p_e >= p + 1, p_e + 1,\n",
    "                                                       np.where(p_e <= -(p + 1), p_e - 1, p_e))))))\n",
    "\n",
    "    # 计算 y_prime，并更新 'Cover_Type'\n",
    "    data.loc[mask, 'Cover_Type'] = p_e + y_hat\n",
    "\n",
    "    pa[group_number] = p\n",
    "\n",
    "    # 更新 group_number 到下一组\n",
    "    group_number += 1\n",
    "\n",
    "# 将字典 pa 转变为 DataFrame 对象并保存为 .csv 文件\n",
    "df_pa = pd.DataFrame(list(pa.items()), columns=['Number', 'Value'])\n",
    "df_pa.to_csv('histogram_pa.csv', index=False)\n",
    "\n",
    "# 将列表 mp 转变为 DataFrame 对象并保存为 .csv 文件\n",
    "df_mp =pd.DataFrame(mp, columns=['Key'])\n",
    "df_mp.to_csv('histogram_mp.csv', index=False)\n",
    "\n",
    "data.to_csv('/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [7 4 1 3 6 2 5]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "1    4052\n",
      "7    4042\n",
      "4    1858\n",
      "6    1050\n",
      "5    1050\n",
      "2    1040\n",
      "3     908\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv'\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011110111001111101101101110111111111010111100111101010011101111111011101101010011101101111010110111110010110111001101100001000010110111110111101110110111110110111011100111110000111001000110111101011011101101011010100011111001110111011100101100011011011010010001101011010111110111001001011111101100111011110110011100111011101101111101111001101101101110011101101000100100111111111100010011110011010101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv'\n",
    "detected_data = pd.read_csv(file_path)\n",
    "\n",
    "# 计算 y_hat\n",
    "_max = detected_data['Cover_Type'].max()\n",
    "_min = detected_data['Cover_Type'].min()\n",
    "y_hat = (_max + _min) / 2\n",
    "\n",
    "# 计算 pe 值\n",
    "detected_data['pe'] = detected_data['Cover_Type'] - y_hat\n",
    "\n",
    "# 将原有的list类型转化为集合数据类型，提高在其中查找项的速度\n",
    "mp_set = set(mp)\n",
    "W_det = \"\"\n",
    "\n",
    "for group_number, bit in enumerate(watermark):\n",
    "    # 对当前组进行操作\n",
    "    group_data = detected_data[detected_data['group_number'] == group_number]\n",
    "    p = pa[group_number]\n",
    "\n",
    "    a = 0 # count bit = 0\n",
    "    b = 0 # count bit = 1\n",
    "\n",
    "    # 通过将一组条件（每行是否满足要求）应用于数据框并进行求和，避免了逐行运算\n",
    "    mask = ~group_data['primary_key'].isin(mp_set) & ((group_data['pe'] == p+1) | (group_data['pe'] == p-1))\n",
    "    b = mask.sum()\n",
    "    mask = ~group_data['primary_key'].isin(mp_set) & (group_data['pe'] == p)\n",
    "    a = mask.sum()\n",
    "\n",
    "    W_det += '0' if a > b else '1'\n",
    "print(W_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:  1011110101000101001100100010111011111010101000101101010011100001111001100001010001101001101010110001000010110111001001000000000010010101010111101010110100010010111011100111010000110000000000111101011011001101001010100001100001110111010100100100010011011010000000100011010101100110001000000010101000111010110110011100111001101101111101001001101101100010010100101000100100111101111100000011010011010101\n",
      "W_det:  1011110111001111101101101110111111111010111100111101010011101111111011101101010011101101111010110111110010110111001101100001000010110111110111101110110111110110111011100111110000111001000110111101011011101101011010100011111001110111011100101100011011011010010001101011010111110111001001011111101100111011110110011100111011101101111101111001101101101110011101101000100100111111111100010011110011010101\n",
      "Mismatch Percentage: 17.75%\n"
     ]
    }
   ],
   "source": [
    "#计算 BER\n",
    "def mismatch_percentage(W, W_det):\n",
    "    # 首先检查 W 和 W_det 是否长度相同\n",
    "    if len(W) != len(W_det):\n",
    "        print('Error: The lengths of W and W_det are not the same!')\n",
    "        return\n",
    "    # 计算不匹配度\n",
    "    count_mismatch = sum(a != b for a, b in zip(W, W_det))\n",
    "    percentage = count_mismatch / len(W)\n",
    "    return percentage\n",
    "\n",
    "# W = '1010101010'\n",
    "# W_det = '1010001010'\n",
    "print(\"W: \",watermark)\n",
    "print(\"W_det: \",W_det)\n",
    "print(f'Mismatch Percentage: {mismatch_percentage(watermark, W_det):.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
