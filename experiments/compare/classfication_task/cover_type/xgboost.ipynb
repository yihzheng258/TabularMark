{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       590\n",
      "           1       0.78      0.53      0.63       635\n",
      "           2       0.79      0.74      0.76       587\n",
      "           3       0.90      0.97      0.94       619\n",
      "           4       0.79      0.93      0.85       589\n",
      "           5       0.77      0.79      0.78       582\n",
      "           6       0.89      0.95      0.92       598\n",
      "\n",
      "    accuracy                           0.80      4200\n",
      "   macro avg       0.80      0.81      0.80      4200\n",
      "weighted avg       0.80      0.80      0.80      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 验证 tabularmark 的不可感知性\n",
    "\n",
    "# 导入所需的库\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/covtype_with_key.subset.data\"\n",
    "ordinary_data = pd.read_csv(file_path)\n",
    "\n",
    "# 数据预处理\n",
    "X_orignal = ordinary_data.iloc[:,0:-1] \n",
    "y_original = ordinary_data.iloc[:,-1] \n",
    "\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_orignal, y_original, test_size=0.3, random_state=42)\n",
    "\n",
    "y_test = y_test - 1\n",
    "y_train = y_train - 1\n",
    "\n",
    "# 使用 XGBoost 创建模型\n",
    "model = XGBClassifier(n_estimators = 10)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集数据\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 评估模型\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "classification_df = pd.DataFrame(classification_dict).transpose()\n",
    "classification_df = classification_df['f1-score']\n",
    "\n",
    "# 生成适合JSON的dict\n",
    "classification_json = classification_df.to_dict()\n",
    "classification_json['algorithm'] = 'original'\n",
    "\n",
    "# 将数据保存到JSON文件\n",
    "with open('classification_report.json', 'a') as json_file:\n",
    "    json.dump(classification_json, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tabularmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       590\n",
      "           1       0.76      0.56      0.64       635\n",
      "           2       0.80      0.74      0.77       587\n",
      "           3       0.90      0.97      0.93       619\n",
      "           4       0.78      0.92      0.84       589\n",
      "           5       0.80      0.81      0.80       582\n",
      "           6       0.90      0.96      0.93       598\n",
      "\n",
      "    accuracy                           0.81      4200\n",
      "   macro avg       0.80      0.81      0.80      4200\n",
      "weighted avg       0.80      0.81      0.80      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/covtype_with_key.subset.data\"\n",
    "ordinary_data = pd.read_csv(file_path)\n",
    "\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/tabularmark_covertype.data.csv\"\n",
    "watermarked_data = pd.read_csv(file_path)\n",
    "\n",
    "# 数据预处理\n",
    "X_orignal = ordinary_data.iloc[:,0:-1] \n",
    "y_original = ordinary_data.iloc[:,-1] \n",
    "\n",
    "X_watermark = watermarked_data.iloc[:,0:-1] \n",
    "y_watermark = watermarked_data.iloc[:,-1] \n",
    "\n",
    "# 划分训练集和测试集\n",
    "_, X_test, _, y_test = train_test_split(X_orignal, y_original, test_size=0.3, random_state=42)\n",
    "X_train, _, y_train, _ = train_test_split(X_watermark, y_watermark, test_size=0.3, random_state=42)\n",
    "\n",
    "y_test = y_test - 1\n",
    "y_train = y_train - 1\n",
    "\n",
    "# 使用 XGBoost 创建模型\n",
    "model = XGBClassifier(n_estimators = 10)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集数据\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 评估模型\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "classification_df = pd.DataFrame(classification_dict).transpose()\n",
    "classification_df = classification_df['f1-score']\n",
    "\n",
    "# 生成适合JSON的dict\n",
    "classification_json = classification_df.to_dict()\n",
    "classification_json['algorithm'] = 'tabulamark'\n",
    "\n",
    "# 将数据保存到JSON文件\n",
    "with open('classification_report.json', 'a') as json_file:\n",
    "    json.dump(classification_json, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogrammark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.90      0.57       590\n",
      "           1       0.00      0.00      0.00       635\n",
      "           2       0.82      0.30      0.44       587\n",
      "           3       0.85      0.98      0.91       619\n",
      "           4       0.85      0.57      0.68       589\n",
      "           5       0.04      0.01      0.01       582\n",
      "           6       0.41      0.94      0.57       598\n",
      "\n",
      "    accuracy                           0.53      4200\n",
      "   macro avg       0.49      0.53      0.46      4200\n",
      "weighted avg       0.48      0.53      0.46      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/covtype_with_key.subset.data\"\n",
    "ordinary_data = pd.read_csv(file_path)\n",
    "ordinary_data.drop(columns=['primary_key'], inplace=True)\n",
    "\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv\"\n",
    "watermarked_data = pd.read_csv(file_path)\n",
    "watermarked_data.drop(columns=['y_hat'], inplace=True)\n",
    "watermarked_data = watermarked_data.sort_values(by='primary_key')\n",
    "watermarked_data.drop(columns=['primary_key'], inplace=True)\n",
    "watermarked_data.drop(columns=['group_number'], inplace=True)\n",
    "\n",
    "# 数据预处理\n",
    "X_orignal = ordinary_data.iloc[:,0:-1] \n",
    "y_original = ordinary_data.iloc[:,-1] \n",
    "\n",
    "X_watermark = watermarked_data.iloc[:,0:-1] \n",
    "y_watermark = watermarked_data.iloc[:,-1] \n",
    "\n",
    "# 划分训练集和测试集\n",
    "_, X_test, _, y_test = train_test_split(X_orignal, y_original, test_size=0.3, random_state=42)\n",
    "X_train, _, y_train, _ = train_test_split(X_watermark, y_watermark, test_size=0.3, random_state=42)\n",
    "\n",
    "y_test = y_test - 1\n",
    "y_train = y_train - 1\n",
    "\n",
    "# 使用 XGBoost 创建模型\n",
    "model = XGBClassifier(n_estimators = 10)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集数据\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 评估模型\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "classification_df = pd.DataFrame(classification_dict).transpose()\n",
    "classification_df = classification_df['f1-score']\n",
    "\n",
    "# 生成适合JSON的dict\n",
    "classification_json = classification_df.to_dict()\n",
    "classification_json['algorithm'] = 'histogrammark'\n",
    "\n",
    "# 将数据保存到JSON文件\n",
    "with open('classification_report.json', 'a') as json_file:\n",
    "    json.dump(classification_json, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semanticmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       590\n",
      "           1       0.73      0.49      0.59       635\n",
      "           2       0.74      0.56      0.64       587\n",
      "           3       0.78      0.98      0.87       619\n",
      "           4       0.70      0.93      0.80       589\n",
      "           5       0.74      0.73      0.73       582\n",
      "           6       0.89      0.96      0.92       598\n",
      "\n",
      "    accuracy                           0.76      4200\n",
      "   macro avg       0.75      0.76      0.75      4200\n",
      "weighted avg       0.75      0.76      0.75      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/covtype_with_key.subset.data\"\n",
    "ordinary_data = pd.read_csv(file_path)\n",
    "ordinary_data.drop(columns=['primary_key'], inplace=True)\n",
    "\n",
    "file_path = \"/home/zhengyihao/dataset/covertype/semanticmark_covertype.data.csv\"\n",
    "watermarked_data = pd.read_csv(file_path)\n",
    "watermarked_data.drop(columns=['primary_key'], inplace=True)\n",
    "\n",
    "# 数据预处理\n",
    "X_orignal = ordinary_data.iloc[:,0:-1] \n",
    "y_original = ordinary_data.iloc[:,-1] \n",
    "\n",
    "X_watermark = watermarked_data.iloc[:,0:-1] \n",
    "y_watermark = watermarked_data.iloc[:,-1] \n",
    "\n",
    "# 划分训练集和测试集\n",
    "_, X_test, _, y_test = train_test_split(X_orignal, y_original, test_size=0.3, random_state=42)\n",
    "X_train, _, y_train, _ = train_test_split(X_watermark, y_watermark, test_size=0.3, random_state=42)\n",
    "\n",
    "y_test = y_test - 1\n",
    "y_train = y_train - 1\n",
    "\n",
    "# 使用 XGBoost 创建模型\n",
    "model = XGBClassifier(n_estimators = 10)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集数据\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 评估模型\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "classification_df = pd.DataFrame(classification_dict).transpose()\n",
    "classification_df = classification_df['f1-score']\n",
    "\n",
    "# 生成适合JSON的dict\n",
    "classification_json = classification_df.to_dict()\n",
    "classification_json['algorithm'] = 'semanticmark'\n",
    "\n",
    "# 将数据保存到JSON文件\n",
    "with open('classification_report.json', 'a') as json_file:\n",
    "    json.dump(classification_json, json_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
