{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [5 2 1 7 3 6 4]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "5    2000\n",
      "2    2000\n",
      "1    2000\n",
      "7    2000\n",
      "3    2000\n",
      "6    2000\n",
      "4    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "import pandas as pd\n",
    "\n",
    "# 数据集文件路径\n",
    "file_path = '../../../../dataset/compare/covtype_with_key.subset.data'\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path)\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 16 bits Ks:  b80d\n",
      "Generated 16 bits k:  0319\n",
      "要嵌入的水印信息是 0110001011101111111100011000010000111001001000110001010111100001011011111110111101110100010100011100100010001110011100001100100001011011101010100101001001110101100000000000111101011001110110001001011110100010001010111111110001010010010110100110001110000000011110011100011111110100010101110100011111010100110100100000100010110010110111101100110010010100100100101110000011010100001011000000001010000001\n",
      "Count of 1:  190\n",
      "Count of 0:  210\n",
      "水印信息已保存到 semantic_mark.txt\n"
     ]
    }
   ],
   "source": [
    "# 定义用户私钥 Ks\n",
    "import secrets\n",
    "\n",
    "# 生成 16 bits 的随机密钥\n",
    "Ks = secrets.token_hex(2) # 用户私钥\n",
    "k = secrets.token_hex(2) # attribute 对应的私钥\n",
    "\n",
    "print(\"Generated 16 bits Ks: \", Ks)\n",
    "print(\"Generated 16 bits k: \", k)\n",
    "\n",
    "# 保存 Ks 到文件\n",
    "with open('semantic_Ks.txt', 'w') as file:\n",
    "    file.write(Ks)\n",
    "\n",
    "# 保存 k 到文件\n",
    "with open('semantic_k.txt', 'w') as file:\n",
    "    file.write(k)\n",
    "\n",
    "# 生成嵌入水印信息\n",
    "\n",
    "import random\n",
    "\n",
    "# 生成一个长度为 400 的字符串，它由随机的 0 和 1 组成\n",
    "watermark = ''.join(random.choice('01') for _ in range(400))\n",
    "# 打印二进制字符串\n",
    "print(\"要嵌入的水印信息是\",watermark)\n",
    "\n",
    "# 统计二进制字符串中 1 的个数\n",
    "count_1 = watermark.count('1')\n",
    "\n",
    "# 统计二进制字符串中 0 的个数\n",
    "count_0 = watermark.count('0')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Count of 1: \", count_1)\n",
    "print(\"Count of 0: \", count_0)\n",
    "\n",
    "\n",
    "# 保存水印信息到文件\n",
    "with open(\"semantic_mark.txt\", \"w\") as file:\n",
    "    file.write(watermark)\n",
    "\n",
    "print(\"水印信息已保存到 semantic_mark.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.75\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import math\n",
    "\n",
    "L = len(watermark)\n",
    "gamma = 14000 / 400 / 4\n",
    "print(gamma)\n",
    "record_table = {}\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # tP_bytes = bin(row['primary_key'])[2:]\n",
    "    \n",
    "    k_hash = hashlib.blake2b(f\"{row['primary_key']}{k}\".encode()).hexdigest()\n",
    "    Ks_hash = hashlib.blake2b(f\"{Ks}{k_hash}\".encode()).hexdigest()\n",
    "    C = int(Ks_hash,16)\n",
    "    if C % gamma == 0:\n",
    "        zeta = int(hashlib.blake2b(f\"{Ks}{k_hash}{1}\".encode()).hexdigest(),16) % L\n",
    "        # print(zeta)\n",
    "        x = row['Cover_Type']\n",
    "        new_x = math.floor((x + 5)/ 2)\n",
    "        # print(C)\n",
    "        # print(x,\",\",new_x,\" \")\n",
    "        if watermark[zeta] == '1':\n",
    "            data.at[index,'Cover_Type'] = new_x\n",
    "\n",
    "            second_hash = hashlib.blake2b(f\"{new_x}{k}{abs(x - new_x)}\".encode()).hexdigest()\n",
    "            # print(f\"{new_x}{k}{abs(x - new_x)}\")\n",
    "            # print(second_hash)\n",
    "\n",
    "            record_table[k_hash] = second_hash\n",
    "\n",
    "        else:\n",
    "            second_hash = hashlib.blake2b(f\"{x}{k}\".encode()).hexdigest()\n",
    "\n",
    "            record_table[k_hash] = second_hash\n",
    "       \n",
    "\n",
    "# 将字典转换为 DataFrame\n",
    "df_record_table = pd.DataFrame(list(record_table.items()), columns=['K_Hash', 'Second_Hash'])\n",
    "\n",
    "# 保存 DataFrame 到 CSV\n",
    "df_record_table.to_csv('semantic_record_table.csv', index=False)\n",
    "\n",
    "data_file_path = '../../../../dataset/compare/semanticmark_covertype.data.csv'\n",
    "data.to_csv(data_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover_Type的值域:  [5 2 3 1 4 7 6]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "4    2688\n",
      "5    2561\n",
      "3    2193\n",
      "6    1878\n",
      "2    1607\n",
      "7    1561\n",
      "1    1512\n",
      "Name: count, dtype: int64\n",
      "原始Cover_Type的值域:  [5 2 1 7 3 6 4]\n",
      "\n",
      "每个值的大小:\n",
      "Cover_Type\n",
      "5    2000\n",
      "2    2000\n",
      "1    2000\n",
      "7    2000\n",
      "3    2000\n",
      "6    2000\n",
      "4    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '../../../../dataset/compare/semanticmark_covertype.data.csv'\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)\n",
    "\n",
    "file_path = '../../../../dataset/compare/covtype_with_key.data'\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取Cover_Type的值域（唯一值）\n",
    "unique_values = data['Cover_Type'].unique()\n",
    "\n",
    "# 获取每个值的计数\n",
    "value_counts = data['Cover_Type'].value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(\"原始Cover_Type的值域: \", unique_values)\n",
    "print(\"\\n每个值的大小:\")\n",
    "print(value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [0, 0], [0, 1], [2, 0], [1, 0], [1, 0], [0, 2], [3, 0], [0, 2], [0, 0], [0, 1], [2, 0], [0, 2], [0, 1], [0, 2], [0, 2], [0, 2], [0, 2], [0, 0], [0, 0], [1, 0], [0, 0], [1, 0], [0, 2], [0, 0], [1, 0], [1, 0], [1, 0], [1, 0], [0, 2], [2, 0], [0, 0], [2, 0], [1, 0], [0, 3], [0, 3], [0, 1], [2, 0], [2, 0], [0, 2], [0, 0], [0, 0], [0, 2], [2, 0], [1, 0], [1, 0], [0, 1], [0, 3], [1, 0], [1, 0], [2, 0], [0, 1], [0, 0], [0, 0], [2, 0], [0, 2], [0, 2], [0, 2], [0, 0], [0, 0], [2, 0], [0, 0], [2, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 2], [0, 3], [0, 3], [0, 1], [0, 2], [0, 0], [0, 0], [0, 1], [0, 2], [0, 2], [0, 1], [1, 0], [0, 1], [0, 2], [0, 1], [1, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 0], [0, 0], [0, 0], [2, 0], [0, 0], [0, 2], [0, 0], [0, 2], [0, 0], [1, 0], [0, 0], [2, 0], [1, 0], [2, 0], [0, 0], [7, 0], [2, 0], [2, 0], [0, 2], [0, 1], [0, 0], [2, 0], [1, 0], [0, 2], [0, 0], [0, 1], [1, 0], [1, 0], [1, 0], [2, 0], [0, 1], [0, 2], [0, 0], [2, 0], [0, 1], [3, 0], [1, 0], [1, 0], [1, 0], [0, 0], [1, 0], [0, 2], [0, 3], [2, 0], [0, 1], [0, 0], [0, 1], [0, 0], [0, 0], [1, 0], [0, 2], [2, 0], [0, 1], [0, 0], [0, 0], [0, 1], [0, 0], [0, 3], [0, 0], [0, 0], [0, 3], [1, 0], [2, 0], [0, 2], [0, 2], [0, 0], [2, 0], [0, 1], [0, 0], [0, 1], [0, 2], [1, 0], [0, 0], [0, 0], [1, 0], [2, 0], [1, 0], [1, 0], [0, 0], [1, 0], [1, 0], [0, 0], [0, 1], [0, 0], [0, 2], [0, 1], [0, 0], [0, 1], [0, 0], [0, 0], [0, 1], [1, 0], [1, 0], [0, 1], [0, 2], [0, 3], [0, 0], [0, 0], [0, 2], [0, 0], [0, 0], [2, 0], [0, 3], [1, 0], [1, 0], [0, 0], [1, 0], [0, 2], [0, 0], [0, 1], [0, 4], [1, 0], [0, 2], [1, 0], [1, 0], [0, 0], [0, 2], [1, 0], [0, 0], [2, 0], [0, 2], [2, 0], [0, 2], [1, 0], [0, 3], [0, 1], [0, 0], [0, 0], [0, 1], [0, 0], [0, 0], [0, 0], [1, 0], [0, 0], [5, 0], [0, 1], [2, 0], [0, 1], [0, 0], [2, 0], [0, 0], [0, 0], [3, 0], [0, 1], [0, 0], [0, 2], [0, 1], [2, 0], [0, 1], [0, 0], [1, 0], [0, 3], [0, 0], [1, 0], [2, 0], [0, 0], [0, 1], [0, 1], [0, 1], [0, 0], [1, 0], [0, 0], [3, 0], [1, 0], [1, 0], [1, 0], [4, 0], [0, 1], [0, 0], [0, 1], [0, 0], [0, 0], [3, 0], [0, 1], [0, 0], [0, 0], [5, 0], [0, 0], [2, 0], [0, 0], [0, 0], [0, 2], [0, 2], [0, 1], [0, 0], [0, 3], [0, 0], [0, 1], [1, 0], [2, 0], [1, 0], [0, 1], [1, 0], [0, 1], [0, 0], [0, 2], [0, 1], [0, 4], [0, 0], [0, 2], [1, 0], [1, 0], [2, 0], [0, 0], [0, 3], [0, 0], [0, 2], [0, 1], [1, 0], [0, 2], [0, 0], [0, 2], [0, 0], [2, 0], [0, 1], [0, 2], [1, 0], [0, 3], [1, 0], [1, 0], [0, 1], [3, 0], [0, 0], [2, 0], [0, 0], [1, 0], [0, 1], [0, 0], [1, 0], [1, 0], [0, 1], [3, 0], [0, 1], [0, 1], [1, 0], [2, 0], [0, 2], [4, 0], [0, 5], [0, 0], [0, 0], [0, 1], [0, 1], [0, 0], [0, 1], [1, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 0], [1, 0], [0, 0], [0, 1], [2, 0], [4, 0], [0, 2], [2, 0], [0, 0], [0, 0], [2, 0], [0, 1], [1, 0], [3, 0], [0, 2], [0, 0], [0, 0], [0, 2], [2, 0], [0, 2], [0, 1], [0, 1], [0, 0], [0, 0], [0, 0], [1, 0], [1, 0], [0, 2], [0, 2], [1, 0], [0, 0], [0, 0], [0, 0], [1, 0], [0, 0], [2, 0], [4, 0], [0, 2], [0, 0], [0, 1], [0, 1], [0, 0], [1, 0], [1, 0], [1, 0], [1, 0], [0, 0], [1, 0], [1, 0], [0, 1], [2, 0], [0, 0], [0, 0], [1, 0], [1, 0], [1, 0], [0, 0], [0, 0], [0, 3]]\n",
      "0110001011101111111100011000010000111001001000110001010111100001011011111110111101110100010100011100100010001110011100001100100001011011101010100101001001110101100000000000111101011001110110001001011110100010001010111111110001010010010110100110001110000000011110011100011111110100010101110100011111010100110100100000100010110010110111101100110010010100100100101110000011010100001011000000001010000001\n",
      "0110001011101111111101011000010100111001111000110001110111110101111111111111111101110111111110111110100010001110011100001110100001011011111010111111111001110111101100001001111111111001111111101001011110100110101010111111110101011011011110110110011111010000011111011101011111111100010111111100011111011110110100101010110010110010111111101111110110010110100111101111110011011101001111100001001011000111\n",
      "Mismatch Percentage: 18.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 数据集文件路径\n",
    "file_path = '../../../../dataset/compare/semanticmark_covertype.data.csv'\n",
    "\n",
    "# 使用列名列表读取数据\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "count = [[0 for _ in range(2)] for _ in range(L)]\n",
    "# print(count)\n",
    "cnt = 0\n",
    "for index, row in data.iterrows():\n",
    "    k_hash = hashlib.blake2b(f\"{row['primary_key']}{k}\".encode()).hexdigest()\n",
    "    Ks_hash = hashlib.blake2b(f\"{Ks}{k_hash}\".encode()).hexdigest()\n",
    "\n",
    "\n",
    "    C = int(Ks_hash,16)\n",
    "    if C % gamma == 0:\n",
    "        # zeta = int(Ks_hash,16) % L\n",
    "        zeta = int(hashlib.blake2b(f\"{Ks}{k_hash}{1}\".encode()).hexdigest(),16) % L\n",
    "        x = row['Cover_Type']\n",
    "        \n",
    "        \n",
    "        if x == 1 and record_table[k_hash] ==  hashlib.blake2b(f\"{1}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "        elif x == 2 and record_table[k_hash] ==  hashlib.blake2b(f\"{2}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "        elif x == 2 and record_table[k_hash] ==  hashlib.blake2b(f\"{2}{k}{2}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 3 and record_table[k_hash] ==  hashlib.blake2b(f\"{3}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "        elif x == 3 and record_table[k_hash] ==  hashlib.blake2b(f\"{3}{k}{2}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 3 and record_table[k_hash] ==  hashlib.blake2b(f\"{3}{k}{1}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 4 and record_table[k_hash] ==  hashlib.blake2b(f\"{4}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "        elif x == 4 and record_table[k_hash] ==  hashlib.blake2b(f\"{4}{k}{1}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 4 and record_table[k_hash] ==  hashlib.blake2b(f\"{4}{k}{0}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 5 and record_table[k_hash] ==  hashlib.blake2b(f\"{5}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "        elif x == 5 and record_table[k_hash] ==  hashlib.blake2b(f\"{5}{k}{0}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 5 and record_table[k_hash] ==  hashlib.blake2b(f\"{5}{k}{1}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 6 and record_table[k_hash] ==  hashlib.blake2b(f\"{6}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "        elif x == 6 and record_table[k_hash] ==  hashlib.blake2b(f\"{6}{k}{1}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 6 and record_table[k_hash] ==  hashlib.blake2b(f\"{6}{k}{2}\".encode()).hexdigest():\n",
    "            count[zeta][1] += 1\n",
    "        elif x == 7 and record_table[k_hash] ==  hashlib.blake2b(f\"{7}{k}\".encode()).hexdigest():\n",
    "            count[zeta][0] += 1\n",
    "          \n",
    "W_det = \"\"\n",
    "for i in range(L):\n",
    "    if count[i][0] > count[i][1]:\n",
    "        W_det += '0'\n",
    "    else:\n",
    "        W_det += '1'\n",
    "\n",
    "print(count)\n",
    "print(watermark)\n",
    "print(W_det)\n",
    "\n",
    "def mismatch_percentage(W, W_det):\n",
    "    # 首先检查 W 和 W_det 是否长度相同\n",
    "    if len(W) != len(W_det):\n",
    "        print('Error: The lengths of W and W_det are not the same!')\n",
    "        return\n",
    "    # 计算不匹配度\n",
    "    count_mismatch = sum(a != b for a, b in zip(W, W_det))\n",
    "    percentage = count_mismatch / len(W)\n",
    "    return percentage\n",
    "\n",
    "print(f'Mismatch Percentage: {mismatch_percentage(watermark, W_det):.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
