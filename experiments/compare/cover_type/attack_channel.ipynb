{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alteration attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tabularmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 攻击\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/tabularmark_covertype.data.csv')\n",
    "\n",
    "# 确定要扰动数据的数量\n",
    "alter_percentages = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for alter_percentage in alter_percentages:\n",
    "    # 创建数据的深拷贝来扰动，这样就不会影响原始数据\n",
    "    altered_data = data.copy()\n",
    "\n",
    "    # 扰动数据\n",
    "    num_alter = int(len(data) * alter_percentage)\n",
    "    # print(num_alter)\n",
    "    indices_to_alter = np.random.choice(data.index, size=num_alter, replace=False)\n",
    "    altered_data.loc[indices_to_alter, 'Cover_Type'] = np.random.randint(1, 8, size=num_alter)\n",
    "\n",
    "    # 保存结果\n",
    "    altered_data.to_csv(f'/home/zhengyihao/dataset/covertype/tabularmark_alter{int(alter_percentage*100)}.data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter0.data.csv - Mismatch Percentage: 0.00% z-score:20.0\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter10.data.csv - Mismatch Percentage: 5.00% z-score:18.0\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter20.data.csv - Mismatch Percentage: 12.50% z-score:15.0\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter30.data.csv - Mismatch Percentage: 19.50% z-score:12.2\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter40.data.csv - Mismatch Percentage: 25.50% z-score:9.8\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter50.data.csv - Mismatch Percentage: 28.75% z-score:8.5\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter60.data.csv - Mismatch Percentage: 36.25% z-score:5.5\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter70.data.csv - Mismatch Percentage: 37.25% z-score:5.1\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter80.data.csv - Mismatch Percentage: 43.75% z-score:2.5\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter90.data.csv - Mismatch Percentage: 49.25% z-score:0.3\n",
      "File: /home/zhengyihao/dataset/covertype/tabularmark_alter100.data.csv - Mismatch Percentage: 61.00% z-score:-4.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "seed_covertype_map = {}\n",
    "\n",
    "def calculate_mismatch(file_path):\n",
    "    # 定义超参数和变量\n",
    "    n = 400      \n",
    "    gamma = 1/2  \n",
    "    green_cell = 0\n",
    "\n",
    "    # 加载数据\n",
    "    detected_data = pd.read_csv(file_path)\n",
    "\n",
    "    # 加载索引列表和种子列表\n",
    "    with open('tabularmark_index.txt', 'r') as f:\n",
    "        indices = [int(line.strip()) for line in f]\n",
    "    with open('tabularmark_seed.txt', 'r') as f:\n",
    "        seeds = [int(line.strip()) for line in f]\n",
    "\n",
    "    df = detected_data\n",
    "    cover_types = detected_data['Cover_Type'].unique()\n",
    "    cover_types.sort()\n",
    "    # 替换Cover_Type值\n",
    "    for idx, seed in zip(indices, seeds):\n",
    "        \n",
    "        if seed not in seed_covertype_map:\n",
    "            random.seed(seed)\n",
    "            shuffled_cover_types = list(cover_types)\n",
    "            random.shuffle(shuffled_cover_types)\n",
    "\n",
    "            # 划分green_domain和red_domain\n",
    "            half_size = len(shuffled_cover_types) // 2\n",
    "            green_domain = shuffled_cover_types[:half_size]\n",
    "            \n",
    "            # 将种子和对应的green_domain保存到字典里\n",
    "            seed_covertype_map[seed] = green_domain\n",
    "        else:\n",
    "            # 如果已经存在，直接从字典中取出green_domain\n",
    "            green_domain = seed_covertype_map[seed]\n",
    "\n",
    "        if df.loc[idx, 'Cover_Type'] in green_domain:\n",
    "            green_cell += 1\n",
    "\n",
    "        # if seed == 1570787129:\n",
    "        #     print(green_domain)\n",
    "\n",
    "    # 计算并返回不匹配度\n",
    "    percentage = (n - green_cell) / n\n",
    "    z_score = (green_cell - n/2) / math.sqrt(n/4)\n",
    "    return percentage,z_score\n",
    "\n",
    "\n",
    "# 计算并打印各个扰动数据的不匹配度\n",
    "file_paths = [f'/home/zhengyihao/dataset/covertype/tabularmark_alter{int(percentage*100)}.data.csv' \n",
    "              for percentage in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    mismatch_percentage,z_score = calculate_mismatch(file_path)\n",
    "    \n",
    "    print(f'File: {file_path} - Mismatch Percentage: {mismatch_percentage:.2%}',f\"z-score:{z_score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogrammark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 攻击\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/histogrammark_covertype.data.csv')\n",
    "\n",
    "# 确定要扰动数据的数量\n",
    "alter_percentages = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for alter_percentage in alter_percentages:\n",
    "    # 创建数据的深拷贝来扰动，这样就不会影响原始数据\n",
    "    altered_data = data.copy()\n",
    "\n",
    "    # 扰动数据\n",
    "    num_alter = int(len(data) * alter_percentage)\n",
    "    indices_to_alter = np.random.choice(data.index, size=num_alter, replace=False)\n",
    "    altered_data.loc[indices_to_alter, 'Cover_Type'] = np.random.randint(1, 8, size=num_alter)\n",
    "\n",
    "    # 保存结果\n",
    "    altered_data.to_csv(f'/home/zhengyihao/dataset/covertype/histogrammark_alter{int(alter_percentage*100)}.data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter0.data.csv - Mismatch Percentage: 17.75%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter10.data.csv - Mismatch Percentage: 19.00%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter20.data.csv - Mismatch Percentage: 21.00%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter30.data.csv - Mismatch Percentage: 21.00%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter40.data.csv - Mismatch Percentage: 27.00%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter50.data.csv - Mismatch Percentage: 30.25%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter60.data.csv - Mismatch Percentage: 34.00%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter70.data.csv - Mismatch Percentage: 35.50%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter80.data.csv - Mismatch Percentage: 39.75%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter90.data.csv - Mismatch Percentage: 46.00%\n",
      "File: /home/zhengyihao/dataset/covertype/histogrammark_alter100.data.csv - Mismatch Percentage: 50.75%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "def calculate_mismatch(file_path):\n",
    "    detected_data = pd.read_csv(file_path)\n",
    "\n",
    "    # 读取 histogram_pa.csv 并将其转换为字典\n",
    "    df_pa = pd.read_csv('histogram_pa.csv')\n",
    "    pa = dict(zip(df_pa['Number'], df_pa['Value']))\n",
    "\n",
    "    # 读取 histogram_mp.csv 并将其转换为列表\n",
    "    df_mp = pd.read_csv('histogram_mp.csv')\n",
    "    mp = df_mp['Key'].tolist()\n",
    "\n",
    "    watermark = \"\"\n",
    "\n",
    "    with open(\"histogram_mark.txt\", \"r\") as file:\n",
    "        watermark = file.read()\n",
    "\n",
    "    # 计算 y_hat\n",
    "    _max = detected_data['Cover_Type'].max()\n",
    "    _min = detected_data['Cover_Type'].min()\n",
    "    y_hat = (_max + _min) / 2\n",
    "\n",
    "    # 计算 pe 值\n",
    "    detected_data['pe'] = detected_data['Cover_Type'] - y_hat\n",
    "\n",
    "    # 将原有的list类型转化为集合数据类型，提高在其中查找项的速度\n",
    "    mp_set = set(mp)\n",
    "    W_det = \"\"\n",
    "\n",
    "    for group_number, bit in enumerate(watermark):\n",
    "        # 对当前组进行操作\n",
    "        group_data = detected_data[detected_data['group_number'] == group_number]\n",
    "        p = pa[group_number]\n",
    "\n",
    "        a = 0 # count bit = 0\n",
    "        b = 0 # count bit = 1\n",
    "\n",
    "        # 通过将一组条件（每行是否满足要求）应用于数据框并进行求和，避免了逐行运算\n",
    "        mask = ~group_data['primary_key'].isin(mp_set) & ((group_data['pe'] == p+1) | (group_data['pe'] == p-1))\n",
    "        b = mask.sum()\n",
    "        mask = ~group_data['primary_key'].isin(mp_set) & (group_data['pe'] == p)\n",
    "        a = mask.sum()\n",
    "\n",
    "        W_det += '0' if a > b else '1'\n",
    "\n",
    "    # 首先检查 W 和 W_det 是否长度相同\n",
    "    if len(watermark) != len(W_det):\n",
    "        print('Error: The lengths of W and W_det are not the same!')\n",
    "        return\n",
    "    # 计算不匹配度\n",
    "    count_mismatch = sum(a != b for a, b in zip(watermark, W_det))\n",
    "    percentage = count_mismatch / len(watermark)\n",
    "    return percentage\n",
    "\n",
    "\n",
    "# 计算并打印各个扰动数据的不匹配度\n",
    "file_paths = [f'/home/zhengyihao/dataset/covertype/histogrammark_alter{int(percentage*100)}.data.csv' \n",
    "              for percentage in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    mismatch_percentage = calculate_mismatch(file_path)\n",
    "    \n",
    "    print(f'File: {file_path} - Mismatch Percentage: {mismatch_percentage:.2%}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semanticmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter0.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter10.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter20.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter30.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter40.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter50.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter60.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter70.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter80.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter90.data.csv\n",
      "Finish produce  /home/zhengyihao/dataset/covertype/semanticmark_alter100.data.csv\n"
     ]
    }
   ],
   "source": [
    "# 攻击\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('/home/zhengyihao/dataset/covertype/semanticmark_covertype.data.csv')\n",
    "\n",
    "# 确定要扰动数据的数量\n",
    "alter_percentages = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for alter_percentage in alter_percentages:\n",
    "    # 创建数据的深拷贝来扰动，这样就不会影响原始数据\n",
    "    altered_data = data.copy()\n",
    "\n",
    "    # 扰动数据\n",
    "    num_alter = int(len(data) * alter_percentage)\n",
    "    indices_to_alter = np.random.choice(data.index, size=num_alter, replace=False)\n",
    "    altered_data.loc[indices_to_alter, 'Cover_Type'] = np.random.randint(1, 8, size=num_alter)\n",
    "    # altered_data.loc[indices_to_alter, 'Cover_Type'] = altered_data.loc[indices_to_alter, 'Cover_Type'] - 1\n",
    "    # altered_data.loc[indices_to_alter, 'Cover_Type'] = altered_data.loc[indices_to_alter, 'Cover_Type'] % 7\n",
    "    # altered_data.loc[indices_to_alter, 'Cover_Type'] = altered_data.loc[indices_to_alter, 'Cover_Type'] + 1\n",
    "\n",
    "    # 保存结果\n",
    "    altered_data.to_csv(f'/home/zhengyihao/dataset/covertype/semanticmark_alter{int(alter_percentage*100)}.data.csv', index=False)\n",
    "\n",
    "    print(\"Finish produce \",f\"/home/zhengyihao/dataset/covertype/semanticmark_alter{int(alter_percentage*100)}.data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter0.data.csv - Mismatch Percentage: 18.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter10.data.csv - Mismatch Percentage: 20.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter20.data.csv - Mismatch Percentage: 24.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter30.data.csv - Mismatch Percentage: 24.50%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter40.data.csv - Mismatch Percentage: 27.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter50.data.csv - Mismatch Percentage: 28.50%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter60.data.csv - Mismatch Percentage: 32.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter70.data.csv - Mismatch Percentage: 35.75%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter80.data.csv - Mismatch Percentage: 35.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter90.data.csv - Mismatch Percentage: 41.00%\n",
      "File: /home/zhengyihao/dataset/covertype/semanticmark_alter100.data.csv - Mismatch Percentage: 45.75%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import hashlib\n",
    "\n",
    "# 从文件中读取 Ks\n",
    "with open('semantic_Ks.txt', 'r') as file:\n",
    "    Ks = file.read()\n",
    "\n",
    "# 从文件中读取 k\n",
    "with open('semantic_k.txt', 'r') as file:\n",
    "    k = file.read()\n",
    "\n",
    "df_record_table = pd.read_csv('semantic_record_table.csv')\n",
    "record_table = dict(zip(df_record_table['K_Hash'], df_record_table['Second_Hash']))\n",
    "\n",
    "\n",
    "def calculate_mismatch(file_path):\n",
    "    # 使用列名列表读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    watermark = \"\"\n",
    "\n",
    "    with open(\"semantic_mark.txt\", \"r\") as file:\n",
    "        watermark = file.read()\n",
    "\n",
    "    L = len(watermark)\n",
    "    gamma = 14000 / 400 / 4\n",
    "\n",
    "    count = [[0 for _ in range(2)] for _ in range(L)]\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        k_hash = hashlib.blake2b(f\"{row['primary_key']}{k}\".encode()).hexdigest()\n",
    "        Ks_hash = hashlib.blake2b(f\"{Ks}{k_hash}\".encode()).hexdigest()\n",
    "\n",
    "\n",
    "        C = int(Ks_hash,16)\n",
    "        if C % gamma == 0:\n",
    "            # zeta = int(Ks_hash,16) % L\n",
    "            zeta = int(hashlib.blake2b(f\"{Ks}{k_hash}{1}\".encode()).hexdigest(),16) % L\n",
    "            x = row['Cover_Type']\n",
    "            # print(f\"{row['primary_key']}\")\n",
    "            # print(k)\n",
    "            # print(k_hash)\n",
    "            # print(\"************\")\n",
    "            # determine the watermark bit\n",
    "            if x == 1 and record_table[k_hash] ==  hashlib.blake2b(f\"{1}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            elif x == 2 and record_table[k_hash] ==  hashlib.blake2b(f\"{2}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            elif x == 2 and record_table[k_hash] ==  hashlib.blake2b(f\"{2}{k}{2}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 3 and record_table[k_hash] ==  hashlib.blake2b(f\"{3}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            elif x == 3 and record_table[k_hash] ==  hashlib.blake2b(f\"{3}{k}{2}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 3 and record_table[k_hash] ==  hashlib.blake2b(f\"{3}{k}{1}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 4 and record_table[k_hash] ==  hashlib.blake2b(f\"{4}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            elif x == 4 and record_table[k_hash] ==  hashlib.blake2b(f\"{4}{k}{1}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 4 and record_table[k_hash] ==  hashlib.blake2b(f\"{4}{k}{0}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 5 and record_table[k_hash] ==  hashlib.blake2b(f\"{5}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            elif x == 5 and record_table[k_hash] ==  hashlib.blake2b(f\"{5}{k}{0}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 5 and record_table[k_hash] ==  hashlib.blake2b(f\"{5}{k}{1}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 6 and record_table[k_hash] ==  hashlib.blake2b(f\"{6}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            elif x == 6 and record_table[k_hash] ==  hashlib.blake2b(f\"{6}{k}{1}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 6 and record_table[k_hash] ==  hashlib.blake2b(f\"{6}{k}{2}\".encode()).hexdigest():\n",
    "                count[zeta][1] += 1\n",
    "            elif x == 7 and record_table[k_hash] ==  hashlib.blake2b(f\"{7}{k}\".encode()).hexdigest():\n",
    "                count[zeta][0] += 1\n",
    "            \n",
    "            # if zeta == 0:\n",
    "            #     print(x)\n",
    "                # print(\"********\")\n",
    "            # break\n",
    "            # cnt += 1\n",
    "            # if cnt == 3:\n",
    "            #     break\n",
    "    W_det = \"\"\n",
    "    for i in range(L):\n",
    "        if count[i][0] > count[i][1]:\n",
    "            W_det += '0'\n",
    "        else:\n",
    "            W_det += '1'\n",
    "    # 首先检查 W 和 W_det 是否长度相同\n",
    "    if len(watermark) != len(W_det):\n",
    "        print('Error: The lengths of W and W_det are not the same!')\n",
    "        return\n",
    "    # 计算不匹配度\n",
    "    count_mismatch = sum(a != b for a, b in zip(watermark, W_det))\n",
    "    percentage = count_mismatch / len(watermark)\n",
    "\n",
    "    # print(count)\n",
    "    # print(watermark)\n",
    "    # print(W_det)\n",
    "\n",
    "    return percentage\n",
    "\n",
    "\n",
    "\n",
    "# 计算并打印各个扰动数据的不匹配度\n",
    "file_paths = [f'/home/zhengyihao/dataset/covertype/semanticmark_alter{int(percentage*100)}.data.csv' \n",
    "              for percentage in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    mismatch_percentage = calculate_mismatch(file_path)\n",
    "    \n",
    "    print(f'File: {file_path} - Mismatch Percentage: {mismatch_percentage:.2%}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
